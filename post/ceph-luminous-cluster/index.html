<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>ceph-luminous-cluster - 一个小破站</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Geo" /><meta name="description" content="ceph概述 Ceph 是一个分布式存储系统，独一无二地用统一的系统—Ceph 存储集群，提供了对象存储，块存储和文件存储三种功能。Ceph 的存储集群基" /><meta name="keywords" content="sre, kubernetes, golang" />






<meta name="generator" content="Hugo 0.61.0 with theme even" />


<link rel="canonical" href="https://www.bestsre.com/post/ceph-luminous-cluster/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.94a695c4.min.css" rel="stylesheet">



<meta property="og:title" content="ceph-luminous-cluster" />
<meta property="og:description" content="ceph概述 Ceph 是一个分布式存储系统，独一无二地用统一的系统—Ceph 存储集群，提供了对象存储，块存储和文件存储三种功能。Ceph 的存储集群基" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.bestsre.com/post/ceph-luminous-cluster/" />
<meta property="article:published_time" content="2018-04-15T16:33:24+08:00" />
<meta property="article:modified_time" content="2018-04-15T16:33:24+08:00" />
<meta itemprop="name" content="ceph-luminous-cluster">
<meta itemprop="description" content="ceph概述 Ceph 是一个分布式存储系统，独一无二地用统一的系统—Ceph 存储集群，提供了对象存储，块存储和文件存储三种功能。Ceph 的存储集群基">
<meta itemprop="datePublished" content="2018-04-15T16:33:24&#43;08:00" />
<meta itemprop="dateModified" content="2018-04-15T16:33:24&#43;08:00" />
<meta itemprop="wordCount" content="3065">



<meta itemprop="keywords" content="Ceph," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="ceph-luminous-cluster"/>
<meta name="twitter:description" content="ceph概述 Ceph 是一个分布式存储系统，独一无二地用统一的系统—Ceph 存储集群，提供了对象存储，块存储和文件存储三种功能。Ceph 的存储集群基"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">叁輪體空</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">叁輪體空</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">ceph-luminous-cluster</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-04-15 </span>
        <div class="post-category">
            <a href="/categories/ceph/"> Ceph </a>
            <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"> 分布式文件系统 </a>
            </div>
          <span class="more-meta"> 约 3065 字 </span>
          <span class="more-meta"> 预计阅读 7 分钟 </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#heading-2">基础环境</a>
      <ul>
        <li><a href="#hosts">hosts</a></li>
        <li><a href="#ceph-yum">所有节点导入ceph yum源</a></li>
        <li><a href="#cephsudo">所有节点添加ceph用户,并赋予sudo权限</a></li>
      </ul>
    </li>
    <li><a href="#heading-3">部署集群</a>
      <ul>
        <li><a href="#ceph-deploy">安装ceph-deploy</a></li>
        <li><a href="#heading-4">在管理节点，创建集群</a></li>
        <li><a href="#-ceph-">更改生成的 ceph 集群配置文件</a></li>
        <li><a href="#-ceph">所有节点安装 ceph</a></li>
        <li><a href="#ceph-monitor-node">初始化ceph monitor node</a></li>
        <li><a href="#osd">osd部署</a></li>
        <li><a href="#heading-5">部署完成，查看集群状态</a></li>
        <li><a href="#ceph-mgr">配置ceph-mgr</a></li>
        <li><a href="#ceph-fs">部署ceph-fs</a></li>
        <li><a href="#fs">挂载fs</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
  <div class="post-outdated">
    <div class="warn">
      <p>【注意】最后更新于 <span class="timeago" datetime="2018-04-15T16:33:24" title="April 15, 2018">April 15, 2018</span>，文中内容可能已过时，请谨慎使用。</p>
    </div>
  </div>
    <div class="post-content">
      <h1 id="ceph">ceph概述</h1>
<p>Ceph 是一个分布式存储系统，独一无二地用统一的系统—Ceph 存储集群，提供了对象存储，块存储和文件存储三种功能。Ceph 的存储集群基于 RADOS，提供了极大伸缩性—供成千用户访问 PB 乃至 EB 级的数据。 Ceph 节点以普通硬件和智能守护进程作为支撑点， Ceph 存储集群组织起了大量节点，它们之间靠相互通讯来复制数据、同时采用 CRUSH 算法动态地重分布数据。
Ceph 有很多术语，了解这些术语，对理解 Ceph 的体系结构是非常重要的。Ceph 的常见术语。</p>
<table>
<thead>
<tr>
<th align="center">名词</th>
<th align="center">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">RADOSGW</td>
<td align="center">对象网关守护进程</td>
</tr>
<tr>
<td align="center">RBD</td>
<td align="center">块存储</td>
</tr>
<tr>
<td align="center">CEPHFS</td>
<td align="center">文件存储</td>
</tr>
<tr>
<td align="center">LIBRADOS</td>
<td align="center">和 RADOS 交互的基本库 librados，Ceph 通过原生协议和 RADOS 交互，Ceph 把这种功能封装进了 librados 库，这样你就能定制自己的客户端</td>
</tr>
<tr>
<td align="center">RADOS</td>
<td align="center">存储集群</td>
</tr>
<tr>
<td align="center">OSD</td>
<td align="center">Object Storage Device,RADOS 的组件，用于存储资源</td>
</tr>
<tr>
<td align="center">Monitor</td>
<td align="center">监视器,RADOS 的组件，维护整个 Ceph 集群的全局状态</td>
</tr>
<tr>
<td align="center">MDS</td>
<td align="center">Ceph 元数据服务器,为 Ceph 文件系统存储元数据</td>
</tr>
</tbody>
</table>
<h1 id="heading">环境节点规划</h1>
<p>Ceph分布式存储集群由若干组件组成，包括：<code>Ceph Monitor</code>、<code>Ceph OSD</code>和<code>Ceph MDS</code>，其中如果你仅使用对象存储和块存储时，MDS不是必须的，仅当你要用到Cephfs时，MDS才是需要安装的。我们这需要安装MDS。</p>
<p>CephRBD是否支持多Pod同时挂载呢？<a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes">官方文档</a>中给出了否定的答案: 基于CephRBD的Persistent Volume仅支持两种accessmode：ReadWriteOnce和ReadOnlyMany，不支持ReadWriteMany。</p>
<p>Ceph的安装模型与k8s有些类似，也是通过一个deploy node远程操作其他Node以create、prepare和activate各个Node上的Ceph组件</p>
<blockquote>
<p>资源有限，在k8s集群节点中部署ceph集群，后面的hosts还是沿用k8s集群的，可能会有些难识别</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center"><strong>节点 name</strong></th>
<th>主机名</th>
<th align="center"><strong>节点 IP</strong></th>
<th align="center"><strong>配置</strong></th>
<th align="center"><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">ceph-mon-0</td>
<td>node-01</td>
<td align="center">172.24.10.20</td>
<td align="center">centos7.4</td>
<td align="center">管理节点，监视器 monitor,mds</td>
</tr>
<tr>
<td align="center">ceph-mon-1</td>
<td>node-02</td>
<td align="center">172.24.10.21</td>
<td align="center">centos7.4</td>
<td align="center">监视器 monitor,mds,client</td>
</tr>
<tr>
<td align="center">ceph-mon-2</td>
<td>node-03</td>
<td align="center">172.24.10.22</td>
<td align="center">centos7.4</td>
<td align="center">监视器 monitor,mds</td>
</tr>
<tr>
<td align="center">ceph-osd-0</td>
<td>node-01</td>
<td align="center">172.24.10.20</td>
<td align="center">20G</td>
<td align="center">存储节点 osd</td>
</tr>
<tr>
<td align="center">ceph-osd-1</td>
<td>node-02</td>
<td align="center">172.24.10.21</td>
<td align="center">20G</td>
<td align="center">存储节点 osd</td>
</tr>
<tr>
<td align="center">ceph-osd-2</td>
<td>node-03</td>
<td align="center">172.24.10.22</td>
<td align="center">20G</td>
<td align="center">存储节点 osd</td>
</tr>
<tr>
<td align="center">ceph-osd-3</td>
<td>node-04</td>
<td align="center">172.24.10.23</td>
<td align="center">20G</td>
<td align="center">存储节点 osd</td>
</tr>
<tr>
<td align="center">ceph-osd-4</td>
<td>node-05</td>
<td align="center">172.24.10.24</td>
<td align="center">20G</td>
<td align="center">存储节点 osd</td>
</tr>
<tr>
<td align="center">ceph-osd-5</td>
<td>node-06</td>
<td align="center">172.24.10.25</td>
<td align="center">20G</td>
<td align="center">存储节点 osd</td>
</tr>
</tbody>
</table>
<h1 id="heading-1">集群部署</h1>
<h2 id="heading-2">基础环境</h2>
<h3 id="hosts">hosts</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">~<span class="o">]</span><span class="c1"># cat /etc/hosts</span>
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

172.24.10.20  node-01
172.24.10.21  node-02
172.24.10.22  node-03
172.24.10.23  node-04
172.24.10.24  node-05
172.24.10.25  node-06
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>同时管理节点和其他节点做好ssh-key免密码登陆</p>
</blockquote>
<h3 id="ceph-yum">所有节点导入ceph yum源</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">~<span class="o">]</span><span class="c1"># yum install epel-release -y &amp;&amp; yum upgrade -y</span>
~<span class="o">]</span><span class="c1"># rpm -Uvh https://download.ceph.com/rpm-luminous/el7/noarch/ceph-release-1-1.el7.noarch.rpm</span>
~<span class="o">]</span><span class="c1"># ansible ceph -a &#39;rpm -Uvh https://download.ceph.com/rpm-luminous/el7/noarch/ceph-release-1-1.el7.noarch.rpm&#39; # 批量安装</span> 

<span class="c1"># 官方源太慢，后面构建集群安装包各种超时</span>
<span class="o">[</span>Ceph<span class="o">]</span>
<span class="nv">name</span><span class="o">=</span>Ceph packages <span class="k">for</span> <span class="nv">$basearch</span>
<span class="nv">baseurl</span><span class="o">=</span>http://mirrors.aliyun.com/ceph/rpm-luminous/el7/<span class="nv">$basearch</span>
<span class="nv">enabled</span><span class="o">=</span><span class="m">1</span>
<span class="nv">gpgcheck</span><span class="o">=</span><span class="m">1</span>
<span class="nv">type</span><span class="o">=</span>rpm-md
<span class="nv">gpgkey</span><span class="o">=</span>https://download.ceph.com/keys/release.asc

<span class="o">[</span>Ceph-noarch<span class="o">]</span>
<span class="nv">name</span><span class="o">=</span>Ceph noarch packages
<span class="nv">baseurl</span><span class="o">=</span>http://mirrors.aliyun.com/ceph/rpm-luminous/el7/noarch
<span class="nv">enabled</span><span class="o">=</span><span class="m">1</span>
<span class="nv">gpgcheck</span><span class="o">=</span><span class="m">1</span>
<span class="nv">type</span><span class="o">=</span>rpm-md
<span class="nv">gpgkey</span><span class="o">=</span>https://download.ceph.com/keys/release.asc

<span class="o">[</span>ceph-source<span class="o">]</span>
<span class="nv">name</span><span class="o">=</span>Ceph <span class="nb">source</span> packages
<span class="nv">baseurl</span><span class="o">=</span>http://mirrors.aliyun.com/ceph/rpm-luminous/el7/SRPMS
<span class="nv">enabled</span><span class="o">=</span><span class="m">1</span>
<span class="nv">gpgcheck</span><span class="o">=</span><span class="m">1</span>
<span class="nv">type</span><span class="o">=</span>rpm-md
<span class="nv">gpgkey</span><span class="o">=</span>https://download.ceph.com/keys/release.asc

<span class="c1"># ansible ceph -m copy -a &#39;src=/etc/yum.repos.d/ceph.repo dest=/etc/yum.repos.d/ceph.repo&#39;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="cephsudo">所有节点添加ceph用户,并赋予sudo权限</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 创建密码</span>
python -c <span class="s2">&#34;from passlib.hash import sha512_crypt; import getpass; print sha512_crypt.encrypt(getpass.getpass())&#34;</span>
Password: ceph
<span class="nv">$6</span><span class="nv">$rounds</span><span class="o">=</span>656000<span class="nv">$PZshbGs2TMKtUgB1</span><span class="nv">$LTdZj9xxHsJH5wRNSLYQL8CH7bAaE4415g</span>/aRZD39RJiRrPx.Bzu19Y5/aOqQuFUunr7griuDN7BAlcTOkuw81
<span class="c1"># 本机sudo</span>
visudo 
Defaults:ceph <span class="nv">timestamp_timeout</span><span class="o">=</span>-1
ceph    <span class="nv">ALL</span><span class="o">=</span><span class="o">(</span>root<span class="o">)</span>     NOPASSWD:ALL

<span class="c1"># ansible创建用户密码yaml</span>
~<span class="o">]</span><span class="c1"># vim user.yml</span>             
- hosts: ceph
  remote_user: root
  tasks:
  - name: add user
    user: <span class="nv">name</span><span class="o">=</span>ceph <span class="nv">password</span><span class="o">=</span><span class="s1">&#39;$6$rounds=656000$PZshbGs2TMKtUgB1$LTdZj9xxHsJH5wRNSLYQL8CH7bAaE4415g/aRZD39RJiRrPx.Bzu19Y5/aOqQuFUunr7griuDN7BAlcTOkuw81&#39;</span>
  - name: sudo config
    copy: <span class="nv">src</span><span class="o">=</span>/etc/sudoers <span class="nv">dest</span><span class="o">=</span>/etc/sudoers
  - name: sync ssh key
    authorized_key: <span class="nv">user</span><span class="o">=</span>ceph <span class="nv">state</span><span class="o">=</span>present <span class="nv">exclusive</span><span class="o">=</span>yes <span class="nv">key</span><span class="o">=</span><span class="s1">&#39;{{lookup(&#39;</span>file<span class="s1">&#39;, &#39;</span>/home/ceph/.ssh/id_rsa.pub<span class="s1">&#39;)}}&#39;</span>
<span class="c1"># 运行playbook</span>
ansible-playbook user.yml

</code></pre></td></tr></table>
</div>
</div><h2 id="heading-3">部署集群</h2>
<h3 id="ceph-deploy">安装ceph-deploy</h3>
<p>在管理节点进行</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">~<span class="o">]</span>$ sudo yum install ceph-deploy
</code></pre></td></tr></table>
</div>
</div><h3 id="heading-4">在管理节点，创建集群</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">~<span class="o">]</span>$ mkdir ceph-cluster
~<span class="o">]</span>$ <span class="nb">cd</span> ceph-cluster 
ceph-cluster<span class="o">]</span>$ ceph-deploy new node-01 node-02 node-03
</code></pre></td></tr></table>
</div>
</div><h3 id="-ceph-">更改生成的 ceph 集群配置文件</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ cat ceph.conf 
<span class="o">[</span>global<span class="o">]</span>
<span class="nv">fsid</span> <span class="o">=</span> 64960081-9cfe-4b6f-a9ae-eb9b2be216bc
<span class="nv">mon_initial_members</span> <span class="o">=</span> node-01, node-02, node-03
<span class="nv">mon_host</span> <span class="o">=</span> 172.24.10.20,172.24.10.21,172.24.10.22
<span class="nv">auth_cluster_required</span> <span class="o">=</span> cephx
<span class="nv">auth_service_required</span> <span class="o">=</span> cephx
<span class="nv">auth_client_required</span> <span class="o">=</span> cephx

<span class="c1">#更改 osd 个数</span>
osd pool default <span class="nv">size</span> <span class="o">=</span> <span class="m">6</span>
<span class="o">[</span>mon<span class="o">]</span>
<span class="c1">#允许 ceph 集群删除 pool</span>
<span class="nv">mon_allow_pool_delete</span> <span class="o">=</span> <span class="nb">true</span>
<span class="o">[</span>mgr<span class="o">]</span>
mgr <span class="nv">modules</span> <span class="o">=</span> dashboard
</code></pre></td></tr></table>
</div>
</div><h3 id="-ceph">所有节点安装 ceph</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"> ~<span class="o">]</span>$ ceph-deploy install --no-adjust-repos node-01 node-02 node-03 node-04 node-05 node-06
 <span class="c1"># 不加--no-adjust-repos 会一直使用ceph-deploy提供的默认的源，很坑</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="ceph-monitor-node">初始化ceph monitor node</h3>
<p>初始化mon，收集所有密钥</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> ceph-cluster/
ceph-deploy mon create-initial
</code></pre></td></tr></table>
</div>
</div><p><strong>报错1：</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">ceph-mon-2 Running command: sudo ceph --cluster<span class="o">=</span>ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-mon-2.asok mon_status
ceph-mon-2 admin_socket: exception getting <span class="nb">command</span> descriptions: <span class="o">[</span>Errno 2<span class="o">]</span> No such file or directory
ceph_deploy.mon mon.ceph-mon-2 monitor is not yet in quorum, tries left: <span class="m">1</span>
ceph_deploy.mon waiting <span class="m">20</span> seconds before retrying
ceph_deploy.mon Some monitors have still not reached quorum:
ceph_deploy.mon ceph-mon-0
ceph_deploy.mon ceph-mon-1
ceph_deploy.mon ceph-mon-2

<span class="c1"># 查看/var/run/ceph目录</span>
<span class="o">]</span>$ ls /var/run/ceph/
ceph-mon.k8s-master-01.asok   // 成节点的主机名的方式命名的

<span class="c1"># 移除错误环境</span>
<span class="o">]</span>$ ceph-deploy mon destroy node-01 node-02 node-03 
还是不行，主机名必须唯一

</code></pre></td></tr></table>
</div>
</div><p><strong>清理环境</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ ceph-deploy purge node-01 node-02 node-03 node-04 node-05 node-06  // 会移除所有与ceph相关的
$ ceph-deploy purgedata node-01 node-02 node-03 node-04 node-05 node-06
$ ceph-deploy forgetkeys
</code></pre></td></tr></table>
</div>
</div><p><strong>报错2</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">[</span>node-03<span class="o">]</span><span class="o">[</span>INFO  <span class="o">]</span> Running command: sudo ceph --cluster<span class="o">=</span>ceph --admin-daemon /var/run/ceph/ceph-mon.node-03.asok mon_status
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> mon.node-03 monitor is not yet in quorum, tries left: <span class="m">5</span>
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> waiting <span class="m">5</span> seconds before retrying
<span class="o">[</span>node-03<span class="o">]</span><span class="o">[</span>INFO  <span class="o">]</span> Running command: sudo ceph --cluster<span class="o">=</span>ceph --admin-daemon /var/run/ceph/ceph-mon.node-03.asok mon_status
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> mon.node-03 monitor is not yet in quorum, tries left: <span class="m">4</span>
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> waiting <span class="m">10</span> seconds before retrying
<span class="o">[</span>node-03<span class="o">]</span><span class="o">[</span>INFO  <span class="o">]</span> Running command: sudo ceph --cluster<span class="o">=</span>ceph --admin-daemon /var/run/ceph/ceph-mon.node-03.asok mon_status
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> mon.node-03 monitor is not yet in quorum, tries left: <span class="m">3</span>
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> waiting <span class="m">10</span> seconds before retrying
<span class="o">[</span>node-03<span class="o">]</span><span class="o">[</span>INFO  <span class="o">]</span> Running command: sudo ceph --cluster<span class="o">=</span>ceph --admin-daemon /var/run/ceph/ceph-mon.node-03.asok mon_status
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> mon.node-03 monitor is not yet in quorum, tries left: <span class="m">2</span>
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> waiting <span class="m">15</span> seconds before retrying
<span class="o">[</span>node-03<span class="o">]</span><span class="o">[</span>INFO  <span class="o">]</span> Running command: sudo ceph --cluster<span class="o">=</span>ceph --admin-daemon /var/run/ceph/ceph-mon.node-03.asok mon_status
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> mon.node-03 monitor is not yet in quorum, tries left: <span class="m">1</span>
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>WARNIN<span class="o">]</span> waiting <span class="m">20</span> seconds before retrying
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>ERROR <span class="o">]</span> Some monitors have still not reached quorum:
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>ERROR <span class="o">]</span> node-02
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>ERROR <span class="o">]</span> node-03
<span class="o">[</span>ceph_deploy.mon<span class="o">]</span><span class="o">[</span>ERROR <span class="o">]</span> node-01
</code></pre></td></tr></table>
</div>
</div><p><strong>解决</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">iptables 策略未通过，可以清空规则，或者添加默认的监听端口6789
</code></pre></td></tr></table>
</div>
</div><p><strong>查看启动服务</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ ps -ef<span class="p">|</span>grep ceph
ceph        <span class="m">4693</span>       <span class="m">1</span>  <span class="m">0</span> 16:45 ?        00:00:00 /usr/bin/ceph-mon -f --cluster ceph --id node-01 --setuser ceph --setgroup ceph
<span class="c1"># 手动停止方法</span>

</code></pre></td></tr></table>
</div>
</div><h3 id="osd">osd部署</h3>
<p><strong>在管理节点上登录到每个 osd 节点，创建 osd 节点的数据存储目录</strong>(老版本)</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># osd-0</span>
ssh node-01
sudo mkdir /var/local/osd0
sudo chown -R ceph.ceph /var/local/osd0

<span class="c1"># osd-1</span>
ssh node-02
sudo mkdir /var/local/osd1
sudo chown -R ceph.ceph /var/local/osd1

<span class="c1"># osd-2</span>
ssh node-03
sudo mkdir /var/local/osd2
sudo chown -R ceph.ceph /var/local/osd2

<span class="c1"># osd-3</span>
ssh node-04
sudo mkdir /var/local/osd3
sudo chown -R ceph.ceph /var/local/osd3

<span class="c1"># osd-4</span>
ssh node-05
sudo mkdir /var/local/osd4
sudo chown -R ceph.ceph /var/local/osd4

<span class="c1"># osd-5</span>
ssh node-06
sudo mkdir /var/local/osd5
sudo chown -R ceph.ceph /var/local/osd5
</code></pre></td></tr></table>
</div>
</div><p><strong>在管理节点上执行命令，使每个 osd 就绪(prepare)</strong>（老版本）</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">ceph-deploy osd prepare node-01:/var/local/osd0 node-02:/var/local/osd1 node-03:/var/local/osd2 node-04:/var/local/osd3 node-05:/var/local/osd4 node-06:/var/local/osd5
<span class="c1"># --overwrite-conf</span>
</code></pre></td></tr></table>
</div>
</div><p><strong>激活每个osd节点</strong>（老版本）</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">ceph-deploy osd activate node-01:/var/local/osd0 node-02:/var/local/osd1 node-03:/var/local/osd2 node-04:/var/local/osd3 node-05:/var/local/osd4 node-06:/var/local/osd5
</code></pre></td></tr></table>
</div>
</div><p><strong>添加激活osd磁盘</strong>(老版本的)</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">ceph-deploy osd create --bluestore node-01:/var/local/osd0 node-02:/var/local/osd1 node-03:/var/local/osd2 node-04:/var/local/osd3 node-05:/var/local/osd4 node-06:/var/local/osd5   
</code></pre></td></tr></table>
</div>
</div><p><strong>新版ceph-deploy直接使用create</strong>
相当于prepare,activate,osd create &ndash;bluestore</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">ceph-deploy osd create --data /dev/sdb node-01
ceph-deploy osd create --data /dev/sdb node-02
ceph-deploy osd create --data /dev/sdb node-03
ceph-deploy osd create --data /dev/sdb node-04
ceph-deploy osd create --data /dev/sdb node-05
ceph-deploy osd create --data /dev/sdb node-06
</code></pre></td></tr></table>
</div>
</div><p><strong>在管理节点把配置文件和 admin 密钥拷贝到管理节点和 Ceph 节点</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">ceph-deploy admin node-01 node-02 node-03 node-04 node-05 node-06
</code></pre></td></tr></table>
</div>
</div><p><strong>在每个节点上赋予 ceph.client.admin.keyring 有操作权限</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"> sudo ansible ceph -a <span class="s1">&#39;chmod +r /etc/ceph/ceph.client.admin.keyring&#39;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="heading-5">部署完成，查看集群状态</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ ceph -s
  cluster:
    id:     64960081-9cfe-4b6f-a9ae-eb9b2be216bc
    health: HEALTH_WARN
            clock skew detected on mon.node-02, mon.node-03
 
  services:
    mon: <span class="m">3</span> daemons, quorum node-01,node-02,node-03
    mgr: node-01<span class="o">(</span>active<span class="o">)</span>, standbys: node-02, node-03
    osd: <span class="m">6</span> osds: <span class="m">6</span> up, <span class="m">6</span> in
 
  data:
    pools:   <span class="m">0</span> pools, <span class="m">0</span> pgs
    objects: <span class="m">0</span> objects, <span class="m">0</span> bytes
    usage:   <span class="m">6337</span> MB used, <span class="m">113</span> GB / <span class="m">119</span> GB avail
    pgs:     
</code></pre></td></tr></table>
</div>
</div><p><strong>health问题解决</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">health: HEALTH_WARN
            clock skew detected on mon.node-02, mon.node-03
这个是时间同步造成的
$ sudo ansible ceph -a <span class="s1">&#39;yum install ntpdate -y&#39;</span>
$ sudo ansible ceph -a <span class="s1">&#39;systemctl stop ntpdate&#39;</span> 
$ sudo ansible ceph -a <span class="s1">&#39;ntpdate time.windows.com&#39;</span>

$ ceph -s
  cluster:
    id:     64960081-9cfe-4b6f-a9ae-eb9b2be216bc
    health: HEALTH_OK
 
  services:
    mon: <span class="m">3</span> daemons, quorum node-01,node-02,node-03
    mgr: node-01<span class="o">(</span>active<span class="o">)</span>, standbys: node-03, node-02
    mds: cephfs-1/1/1 up  <span class="o">{</span><span class="nv">0</span><span class="o">=</span>node-02<span class="o">=</span>up:active<span class="o">}</span>, <span class="m">2</span> up:standby
    osd: <span class="m">6</span> osds: <span class="m">6</span> up, <span class="m">6</span> in
 
  data:
    pools:   <span class="m">2</span> pools, <span class="m">192</span> pgs
    objects: <span class="m">21</span> objects, <span class="m">2246</span> bytes
    usage:   <span class="m">6354</span> MB used, <span class="m">113</span> GB / <span class="m">119</span> GB avail
    pgs:     <span class="m">192</span> active+clean
</code></pre></td></tr></table>
</div>
</div><p>查看状态</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ ceph osd tree
ID  CLASS WEIGHT  TYPE NAME        STATUS REWEIGHT PRI-AFF 
 -1       0.11691 root default                             
 -3       0.01949     host node-01                         
  <span class="m">0</span>   hdd 0.01949         osd.0        up  1.00000 1.00000 
 -5       0.01949     host node-02                         
  <span class="m">1</span>   hdd 0.01949         osd.1        up  1.00000 1.00000 
 -7       0.01949     host node-03                         
  <span class="m">2</span>   hdd 0.01949         osd.2        up  1.00000 1.00000 
 -9       0.01949     host node-04                         
  <span class="m">3</span>   hdd 0.01949         osd.3        up  1.00000 1.00000 
-11       0.01949     host node-05                         
  <span class="m">4</span>   hdd 0.01949         osd.4        up  1.00000 1.00000 
-13       0.01949     host node-06                         
  <span class="m">5</span>   hdd 0.01949         osd.5        up  1.00000 1.00000 
</code></pre></td></tr></table>
</div>
</div><p>查看挂载</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ df -Th        
Filesystem              Type      Size  Used Avail Use% Mounted on
/dev/mapper/centos-root xfs        17G  1.5G   16G   9% /
devtmpfs                devtmpfs  478M     <span class="m">0</span>  478M   0% /dev
tmpfs                   tmpfs     488M     <span class="m">0</span>  488M   0% /dev/shm
tmpfs                   tmpfs     488M  6.6M  482M   2% /run
tmpfs                   tmpfs     488M     <span class="m">0</span>  488M   0% /sys/fs/cgroup
/dev/sda1               xfs      1014M  153M  862M  16% /boot
tmpfs                   tmpfs      98M     <span class="m">0</span>   98M   0% /run/user/0
tmpfs                   tmpfs     488M   48K  488M   1% /var/lib/ceph/osd/ceph-0

<span class="o">]</span>$ cat /var/lib/ceph/osd/ceph-0/type
bluestore
</code></pre></td></tr></table>
</div>
</div><h3 id="ceph-mgr">配置ceph-mgr</h3>
<p>自从ceph 12开始，manager是必须的。应该为每个运行monitor的机器添加一个mgr，否则集群处于WARN状态。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ ceph-deploy mgr create node-01 node-02 node-03
ceph config-key put mgr/dashboard/server_addr 172.24.10.20
ceph config-key put mgr/dashboard/server_port <span class="m">7000</span>
ceph mgr module <span class="nb">enable</span> dashboard 
http://172.24.10.20:7000/

</code></pre></td></tr></table>
</div>
</div><h3 id="ceph-fs">部署ceph-fs</h3>
<p><a href="http://docs.ceph.com/docs/master/rados/operations/placement-groups/">http://docs.ceph.com/docs/master/rados/operations/placement-groups/</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ ceph-deploy mds create node-01 node-02 node-03 
$ ceph osd pool create cephfs_data <span class="m">128</span>
$ ceph osd pool create cephfs_metadata <span class="m">64</span>
$ ceph fs new cephfs cephfs_metadata cephfs_data
$ ceph fs ls
name: cephfs, metadata pool: cephfs_metadata, data pools: <span class="o">[</span>cephfs_data <span class="o">]</span>

$ ceph mds stat 
cephfs-1/1/1 up  <span class="o">{</span><span class="nv">0</span><span class="o">=</span>node-02<span class="o">=</span>up:active<span class="o">}</span>, <span class="m">2</span> up:standby
虽然支持多 active mds并行运行，但官方文档建议保持一个active mds，其他mds作为standby
</code></pre></td></tr></table>
</div>
</div><h3 id="fs">挂载fs</h3>
<p>client是规划在node2上的
在物理机上挂载cephfs可以使用mount命令、mount.ceph(apt-get install ceph-fs-common)或ceph-fuse(apt-get install ceph-fuse)，我们先用mount命令挂载</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ sudo mkdir /data/ceph-storage/ -p
$ sudo chown -R ceph.ceph /data/ceph-storage

$ ceph-authtool -l /etc/ceph/ceph.client.admin.keyring
<span class="o">[</span>client.admin<span class="o">]</span>
        <span class="nv">key</span> <span class="o">=</span> <span class="nv">AQAEKJFa54MlFRAAg76JDhpwlHD1F8J2G76baQ</span><span class="o">=</span><span class="o">=</span>

$ sudo mount -t ceph 172.24.10.21:6789:/ /data/ceph-storage/ -o <span class="nv">name</span><span class="o">=</span>admin,secret<span class="o">=</span><span class="nv">AQAEKJFa54MlFRAAg76JDhpwlHD1F8J2G76baQ</span><span class="o">=</span><span class="o">=</span>

$ df -Th
Filesystem              Type      Size  Used Avail Use% Mounted on
/dev/mapper/centos-root xfs        17G  1.5G   16G   9% /
devtmpfs                devtmpfs  478M     <span class="m">0</span>  478M   0% /dev
tmpfs                   tmpfs     488M     <span class="m">0</span>  488M   0% /dev/shm
tmpfs                   tmpfs     488M  6.7M  481M   2% /run
tmpfs                   tmpfs     488M     <span class="m">0</span>  488M   0% /sys/fs/cgroup
/dev/sda1               xfs      1014M  153M  862M  16% /boot
tmpfs                   tmpfs      98M     <span class="m">0</span>   98M   0% /run/user/0
tmpfs                   tmpfs     488M   48K  488M   1% /var/lib/ceph/osd/ceph-1
tmpfs                   tmpfs      98M     <span class="m">0</span>   98M   0% /run/user/1000
172.24.10.21:6789:/     ceph      120G  6.3G  114G   6% /data/ceph-storage
</code></pre></td></tr></table>
</div>
</div>
    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/ceph/">Ceph</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/use-kubeadm-build-kubernetes-cluster/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">kubeadm部署kubernetes集群</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/mongodb-3.6-%E5%88%86%E7%89%87%E5%A4%8D%E5%88%B6%E9%9B%86%E7%BE%A4/">
            <span class="next-text nav-default">MongoDB 3.6分片复制集群</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://www.bestsre.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2018 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Geo</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  
    <script type="text/javascript" src="/lib/timeago/timeago-3.0.2.min.js"></script>
    <script type="text/javascript" src="/lib/timeago/timeago.locales-3.0.2.min.js"></script>
  <script><!-- NOTE: timeago.js uses the language code format like "zh_CN" (underscore and case sensitive) -->
    var languageCode = "zh-cn".replace(/-/g, '_').replace(/_(.*)/, function ($0, $1) {return $0.replace($1, $1.toUpperCase());});
    timeago().render(document.querySelectorAll('.timeago'), languageCode);
    timeago.cancel();  
  </script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
